from typing import Dict, Any, Optional
import asyncio
import logging
from langchain_openai import ChatOpenAI
from openai import APIConnectionError, InternalServerError, RateLimitError
from config import get_extra_body
from utils.config_manager import get_config_manager
from .mcp_client import McpRouterClient, McpToolCatalog

# Configure logging
logger = logging.getLogger(__name__)


class Processor:
    """
    Processor module: accepts a natural language query and routes to appropriate MCP tools via LLM reasoning.
    Minimal implementation uses LLM to choose server capability and return a structured action plan.
    """
    def __init__(self):
        self.router = McpRouterClient()
        self.catalog = McpToolCatalog(self.router)
        self._config_manager = get_config_manager()
        # åˆå§‹åŒ–ç¼“å­˜å±æ€§
        self._capabilities_cache = None
        self._capabilities_cache_time = 0
        self._cache_timeout = 30  # ç¼“å­˜è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    def _get_llm(self):
        """åŠ¨æ€è·å–LLMå®ä¾‹ä»¥æ”¯æŒé…ç½®çƒ­é‡è½½"""
        api_config = self._config_manager.get_model_api_config('summary')
        return ChatOpenAI(model=api_config['model'], base_url=api_config['base_url'], api_key=api_config['api_key'], temperature=0, extra_body=get_extra_body(api_config['model']) or None)

    async def process(self, query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        # ä½¿ç”¨ç¼“å­˜çš„å·¥å…·èƒ½åŠ›ï¼Œå‡å°‘è·å–å»¶è¿Ÿ
        import time
        current_time = time.time()
        
        if self._capabilities_cache is None or current_time - self._capabilities_cache_time > self._cache_timeout:
            capabilities = await self.catalog.get_capabilities()
            self._capabilities_cache = capabilities
            self._capabilities_cache_time = current_time
            logger.info(f"[MCP] Updated capabilities cache, found {len(capabilities)} tools")
        else:
            capabilities = self._capabilities_cache
            logger.info(f"[MCP] Using cached capabilities, found {len(capabilities)} tools")
        
        # Log MCP capabilities
        logger.info(f"[MCP] Processing query: {query[:100]}...")
        logger.info(f"[MCP] Available capabilities: {len(capabilities)}")
        for cap_id, cap_info in capabilities.items():
            logger.info(f"[MCP]   - {cap_id}: {cap_info.get('title', 'No title')} (status: {cap_info.get('status', 'unknown')})")
        
        tools_brief = "\n".join([f"- {k}: {v['description']} (status={v['status']})" for k, v in capabilities.items()])
        system = (
            "You are a tool routing agent. Given a user task, select one MCP server capability by id and"
            " produce a concise JSON with fields: can_execute (boolean), reason, server_id, tool_calls (list of specific tool names that would be used)."
            " If a server can handle the task, set can_execute=true, provide server_id, and list the specific tools that would be called."
            " If no server fits or status is not online, set can_execute=false with reason."
            " For tool_calls, be specific about which tools from the server would be used (e.g., ['save_memory', 'retrieve_memory'])."
        )
        user = f"Capabilities:\n{tools_brief}\n\nTask: {query}"
        
        # Retryç­–ç•¥ï¼šé‡è¯•2æ¬¡ï¼Œé—´éš”1ç§’ã€2ç§’
        max_retries = 3
        retry_delays = [1, 2]
        text = ""
        
        for attempt in range(max_retries):
            try:
                llm = self._get_llm()
                resp = await llm.ainvoke([
                    {"role": "system", "content": system},
                    {"role": "user", "content": user},
                ])
                text = resp.content.strip()
                break  # æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯
            except (APIConnectionError, InternalServerError, RateLimitError) as e:
                logger.info(f"â„¹ï¸ æ•è·åˆ° {type(e).__name__} é”™è¯¯")
                if attempt < max_retries - 1:
                    wait_time = retry_delays[attempt]
                    logger.warning(f"[MCP] LLMè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})ï¼Œ{wait_time}ç§’åé‡è¯•: {e}")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"[MCP] LLMè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    return {"can_execute": False, "reason": f"LLM error after {max_retries} attempts: {e}"}
            except Exception as e:
                logger.error(f"[MCP] LLMè°ƒç”¨å¤±è´¥: {e}")
                return {"can_execute": False, "reason": f"LLM error: {e}"}
        
        # Log raw LLM response for debugging
        logger.info(f"[MCP] Raw LLM response: {text}")
        
        import json
        try:
            if text.startswith("```"):
                text = text.replace("```json", "").replace("```", "").strip()
            parsed = json.loads(text)
            
            # Ensure can_execute field exists and is boolean
            if 'can_execute' not in parsed:
                # If server_id is provided, assume it can execute
                parsed['can_execute'] = bool(parsed.get('server_id'))
                logger.info(f"[MCP] Missing can_execute field, inferred from server_id: {parsed['can_execute']}")
        except Exception as e:
            logger.error(f"[MCP] JSON parse error: {e}, raw text: {text}")
            parsed = {"can_execute": False, "reason": "LLM parse error", "raw": text}
        
        # Log MCP processing result and execute tools
        if parsed.get('can_execute'):
            server_id = parsed.get('server_id', 'unknown')
            reason = parsed.get('reason', 'no reason provided')
            tool_calls = parsed.get('tool_calls', [])
            
            if tool_calls:
                tools_info = ", ".join([f"'{tool}'" for tool in tool_calls])
                logger.info(f"[MCP] âœ… Query processed successfully using MCP server '{server_id}' with tools: {tools_info}")
                
                # Execute the tools and log results
                tool_results = []
                for tool_name in tool_calls:
                    logger.info(f"[MCP] ğŸ”§ Executing tool: {server_id}.{tool_name}")
                    
                    # Prepare tool arguments based on the query
                    arguments = self._prepare_tool_arguments(tool_name, query)
                    
                    # Call the tool
                    result = await self.router.call_tool(server_id, tool_name, arguments)
                    
                    if result.get('success'):
                        logger.info(f"[MCP] âœ… Tool {tool_name} executed successfully: {result.get('result', 'No result')}")
                        tool_results.append({
                            'tool': tool_name,
                            'success': True,
                            'result': result.get('result')
                        })
                    else:
                        logger.error(f"[MCP] âŒ Tool {tool_name} failed: {result.get('error', 'Unknown error')}")
                        tool_results.append({
                            'tool': tool_name,
                            'success': False,
                            'error': result.get('error')
                        })
                
                # Add tool results to the response
                parsed['tool_results'] = tool_results
            else:
                logger.info(f"[MCP] âœ… Query processed successfully using MCP server '{server_id}' (no specific tools called)")
            
            logger.info(f"[MCP]   Reason: {reason}")
        else:
            reason = parsed.get('reason', 'no reason provided')
            logger.info(f"[MCP] âŒ Query cannot be processed by MCP: {reason}")
        
        return parsed
        
    async def stream_process(self, query: str, context: Optional[Dict[str, Any]] = None):
        """
        æµå¼å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œå®æ—¶è¿”å›å¤„ç†ç»“æœ
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Yields:
            å¤„ç†è¿‡ç¨‹ä¸­çš„å®æ—¶ç»“æœ
        """
        # 1. ä½¿ç”¨ç¼“å­˜çš„å·¥å…·èƒ½åŠ›ï¼Œå‡å°‘è·å–å»¶è¿Ÿ
        import time
        current_time = time.time()
        
        if self._capabilities_cache is None or current_time - self._capabilities_cache_time > self._cache_timeout:
            capabilities = await self.catalog.get_capabilities()
            self._capabilities_cache = capabilities
            self._capabilities_cache_time = current_time
            yield f"ğŸ”„ æ›´æ–°å·¥å…·èƒ½åŠ›ç¼“å­˜ï¼Œå‘ç° {len(capabilities)} ä¸ªå¯ç”¨å·¥å…·\n"
        else:
            capabilities = self._capabilities_cache
            yield f"âœ… ä½¿ç”¨ç¼“å­˜çš„å·¥å…·èƒ½åŠ›ï¼Œå‘ç° {len(capabilities)} ä¸ªå¯ç”¨å·¥å…·\n"
        
        yield f"ğŸ” æ­£åœ¨åˆ†ææŸ¥è¯¢ï¼š{query[:50]}...\n"
        yield f"âœ… å‘ç° {len(capabilities)} ä¸ªå¯ç”¨å·¥å…·\n"
        
        tools_brief = "\n".join([f"- {k}: {v['description']} (status={v['status']})" for k, v in capabilities.items()])
        system = (
            "You are a tool routing agent. Given a user task, select one MCP server capability by id and"
            " produce a concise JSON with fields: can_execute (boolean), reason, server_id, tool_calls (list of specific tool names that would be used)."
            " If a server can handle the task, set can_execute=true, provide server_id, and list the specific tools that would be called."
            " If no server fits or status is not online, set can_execute=false with reason."
            " For tool_calls, be specific about which tools from the server would be used (e.g., ['save_memory', 'retrieve_memory'])."
        )
        user = f"Capabilities:\n{tools_brief}\n\nTask: {query}"
        
        # 2. è°ƒç”¨LLMè¿›è¡Œæµå¼å¤„ç†
        yield "ğŸ¤– æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n"
        
        max_retries = 3
        retry_delays = [1, 2]
        text = ""
        
        for attempt in range(max_retries):
            try:
                llm = self._get_llm()
                
                # ä½¿ç”¨æµå¼è°ƒç”¨
                async for chunk in llm.astream([
                    {"role": "system", "content": system},
                    {"role": "user", "content": user},
                ]):
                    if chunk.content:
                        text += chunk.content
                        yield chunk.content  # å®æ—¶è¿”å›LLMç”Ÿæˆçš„å†…å®¹
                break
            except (APIConnectionError, InternalServerError, RateLimitError) as e:
                yield f"âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼Œ{retry_delays[attempt]}ç§’åé‡è¯•...\n"
                await asyncio.sleep(retry_delays[attempt])
            except Exception as e:
                yield f"âŒ LLMè°ƒç”¨å¤±è´¥ï¼š{e}\n"
                return
        
        yield "\nâœ… LLMåˆ†æå®Œæˆ\n"
        
        # 3. è§£æLLMç»“æœ
        import json
        try:
            if text.startswith("```"):
                text = text.replace("```json", "").replace("```", "").strip()
            parsed = json.loads(text)
            
            # Ensure can_execute field exists and is boolean
            if 'can_execute' not in parsed:
                # If server_id is provided, assume it can execute
                parsed['can_execute'] = bool(parsed.get('server_id'))
        except Exception as e:
            yield f"âŒ JSONè§£æé”™è¯¯ï¼š{e}\n"
            return
        
        # 4. æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if parsed.get('can_execute'):
            server_id = parsed.get('server_id', 'unknown')
            reason = parsed.get('reason', 'no reason provided')
            tool_calls = parsed.get('tool_calls', [])
            
            yield f"âœ… é€‰æ‹©æœåŠ¡å™¨ï¼š{server_id}\n"
            yield f"ğŸ“‹ ä½¿ç”¨å·¥å…·ï¼š{', '.join(tool_calls)}\n"
            
            if tool_calls:
                tool_results = []
                for tool_name in tool_calls:
                    yield f"ğŸ”§ æ­£åœ¨æ‰§è¡Œå·¥å…·ï¼š{tool_name}...\n"
                    
                    # Prepare tool arguments based on the query
                    arguments = self._prepare_tool_arguments(tool_name, query)
                    
                    # Call the tool
                    result = await self.router.call_tool(server_id, tool_name, arguments)
                    
                    if result.get('success'):
                        yield f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ\n"
                        yield f"ğŸ“ ç»“æœï¼š{result.get('result', 'No result')}\n"
                        tool_results.append({
                            'tool': tool_name,
                            'success': True,
                            'result': result.get('result')
                        })
                    else:
                        yield f"âŒ å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥ï¼š{result.get('error', 'Unknown error')}\n"
                        tool_results.append({
                            'tool': tool_name,
                            'success': False,
                            'error': result.get('error')
                        })
                
                # Add tool results to the response
                parsed['tool_results'] = tool_results
            else:
                yield "ğŸ“‹ æ— éœ€æ‰§è¡Œå…·ä½“å·¥å…·\n"
        else:
            reason = parsed.get('reason', 'no reason provided')
            yield f"âŒ æ— æ³•æ‰§è¡Œä»»åŠ¡ï¼š{reason}\n"
        
        # 5. è¿”å›æœ€ç»ˆç»“æœ
        yield "\nğŸ‰ å¤„ç†å®Œæˆï¼\n"
        yield f"ğŸ“Š æœ€ç»ˆç»“æœï¼š{json.dumps(parsed, ensure_ascii=False)}\n"

    def _prepare_tool_arguments(self, tool_name: str, query: str) -> Dict[str, Any]:
        """Prepare arguments for tool calls based on the tool name and query"""
        if tool_name == "save_memory":
            return {
                "content": query,
                "timestamp": "2025-09-24T07:30:00Z",
                "tags": ["user_query", "memory"]
            }
        elif tool_name == "retrieve_memory":
            return {
                "query": query,
                "limit": 5,
                "include_metadata": True
            }
        else:
            return {
                "input": query,
                "parameters": {}
            }


